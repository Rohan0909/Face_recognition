{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8035207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import*\n",
    "from tkinter import ttk\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import os\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27826c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8888\\1443502735.py:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img=img.resize((1530,765),Image.ANTIALIAS)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8888\\1443502735.py:15: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img1=img1.resize((220,220),Image.ANTIALIAS)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8888\\1443502735.py:25: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img3=img3.resize((220,220),Image.ANTIALIAS)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8888\\1443502735.py:34: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img4=img4.resize((220,220),Image.ANTIALIAS)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8888\\1443502735.py:43: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img2=img2.resize((220,220),Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "class face_recognition:\n",
    "    def __init__(self,root):\n",
    "        self.root=root\n",
    "        self.root.geometry(\"1530x765+0+0\")\n",
    "        self.root.title(\"face recognition system\")\n",
    "     #background image \n",
    "        img=Image.open(r'../../../datasets/face_recognition_system/black-background.webp')\n",
    "        img=img.resize((1530,765),Image.ANTIALIAS)\n",
    "        self.photoimg=ImageTk.PhotoImage(img)\n",
    "        bg_img=Label(self.root,image=self.photoimg)\n",
    "        bg_img.place(x=0,y=0,width=1530,height=765)\n",
    "\n",
    "    #photos data\n",
    "        img1=Image.open(r'../../../datasets/face_recognition_system/open.jpg.jfif')\n",
    "        img1=img1.resize((220,220),Image.ANTIALIAS)\n",
    "        self.photoimg1=ImageTk.PhotoImage(img1)\n",
    "\n",
    "        b1=Button(bg_img,image=self.photoimg1,cursor=\"hand2\",command=self.open_img)\n",
    "        b1.place(x=200,y=100,width=220,height=220)\n",
    "        b1_1=Button(bg_img,text=\"TRANING-DATA\",cursor=\"hand2\",command=self.open_img,font=(\"times new roman\",20,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        b1_1.place(x=200,y=320,width=220,height=40)\n",
    "\n",
    "    #prepare data\n",
    "        img3=Image.open(r'../../../datasets/face_recognition_system/reshape.jpg')\n",
    "        img3=img3.resize((220,220),Image.ANTIALIAS)\n",
    "        self.photoimg3=ImageTk.PhotoImage(img3)\n",
    "        b2=Button(bg_img,image=self.photoimg3,cursor=\"hand2\",command=self.reshape)\n",
    "        b2.place(x=450,y=100,width=220,height=220)\n",
    "        b2_2=Button(bg_img,text=\"RESHAPE\",cursor=\"hand2\",command=self.reshape,font=(\"times new roman\",20,\"bold\"),bg=\"White\",fg=\"black\")\n",
    "        b2_2.place(x=450,y=320,width=220,height=40)\n",
    "\n",
    "    #TRain\n",
    "        img4=Image.open(r'../../../datasets/face_recognition_system/train.jpg')\n",
    "        img4=img4.resize((220,220),Image.ANTIALIAS)\n",
    "        self.photoimg4=ImageTk.PhotoImage(img4)\n",
    "        b3=Button(bg_img,image=self.photoimg4,cursor=\"hand2\",command=self.train_classiffier)\n",
    "        b3.place(x=700,y=100,width=220,height=220)\n",
    "        b3_3b3=Button(bg_img,text=\"TRAIN\",cursor=\"hand2\",command=self.train_classiffier,font=(\"times new roman\",20,\"bold\"),bg=\"White\",fg=\"black\")\n",
    "        b3_3b3.place(x=700,y=320,width=220,height=40)\n",
    "\n",
    "    #detect face\n",
    "        img2=Image.open(r'../../../datasets/face_recognition_system/face.jpeg')\n",
    "        img2=img2.resize((220,220),Image.ANTIALIAS)\n",
    "        self.photoimg2=ImageTk.PhotoImage(img2)\n",
    "\n",
    "        b4=Button(bg_img,image=self.photoimg2,cursor=\"hand2\",command=self.face_recog)\n",
    "        b4.place(x=950,y=100,width=220,height=220)\n",
    "        b4_4=Button(bg_img,text=\"RECOGNIZE\",cursor=\"hand2\",command=self.face_recog,font=(\"times new roman\",20,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        b4_4.place(x=950,y=320,width=220,height=40)\n",
    "\n",
    "    #close project\n",
    "        b5=Button(bg_img,text=\"EXIT\",cursor=\"hand2\",command=root.destroy,font=(\"times new roman\",20,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        b5.place(x=600,y=400,width=330,height=40)\n",
    "        \n",
    "#****************************************************************functions************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "#****************show data folder*************************\n",
    "    def open_img(self):\n",
    "        os.startfile(r'../../../datasets/Train')        \n",
    "#***************preparing the data********************************\n",
    "    \n",
    "    def reshape(self):\n",
    "\n",
    "        path = ('../../../datasets/Train/')\n",
    "        face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        for i, filename in enumerate(os.listdir(path)):\n",
    "            os.rename('../../../datasets/Train/' + filename, '../../../datasets/Train/' + \"user.\" + str(i) + \".jpg\")\n",
    "\n",
    "        for l, filename in enumerate(os.listdir(path)):\n",
    "                img=cv2.imread('../../../datasets/Train/user.'+ str(l)+'.jpg')\n",
    "                gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                detectface=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "                for (x,y,w,h) in detectface:\n",
    "                    face_cropped=img[y:y+h,x:x+w]\n",
    "                    BGR2GRAY=cv2.cvtColor(face_cropped,cv2.COLOR_BGR2GRAY)\n",
    "                    cv2.imwrite('../../../datasets/Train/'+str(l)+'.jpg',BGR2GRAY)\n",
    "                    \n",
    "                    \n",
    "        for item in os.listdir(path):\n",
    "            if os.path.isfile(path+item):\n",
    "                im = Image.open(path+item)\n",
    "                f, e = os.path.splitext(path+item)\n",
    "                imResize = im.resize((450,450), Image.ANTIALIAS)\n",
    "                imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
    "        messagebox.showinfo(\"RESULTS\",\"DATA PREPERATION COMPLETED!! YOU CAN TRAIN DATA\")\n",
    "        \n",
    "        \n",
    "#***************Train data********************************\n",
    "\n",
    "    def train_classiffier(self):\n",
    "        data_dir=(r\"../../../datasets/Train\")\n",
    "        path=[os.path.join(data_dir,file) for file in os.listdir(data_dir)]\n",
    "\n",
    "        faces=[]\n",
    "        ids=[] \n",
    "\n",
    "        for image in path:\n",
    "            img=Image.open(image).convert('L')   ####Gray scale\n",
    "            imageNP=np.array(img,'uint8')\n",
    "            id=int(os.path.split(image)[1].split('.')[1])\n",
    "\n",
    "            faces.append(imageNP)\n",
    "            ids.append(id)\n",
    "            cv2.imshow(\"Training\",imageNP)\n",
    "            cv2.waitKey(1)==13\n",
    "        ids=np.array(ids)\n",
    "        \n",
    "#******************************Train the classifier*******************************************    \n",
    "\n",
    "        clf=cv2.face.LBPHFaceRecognizer_create()\n",
    "        clf.train(faces,ids)\n",
    "        clf.write(r\"../../../datasets/N_classifier.xml\")\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Result\",\"training dataset completed!!!!\")\n",
    "        \n",
    "        \n",
    "    def face_recog(self):\n",
    "        \n",
    "        \n",
    "        def draw_boundary(img,classifier,scaleFactor,minNeighbors,color,text,clf,c):\n",
    "            \n",
    "            gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            features=classifier.detectMultiScale(gray_image,scaleFactor,minNeighbors)\n",
    "            \n",
    "            list=[]\n",
    "            coord=[]\n",
    "            for (x,y,w,h) in features:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "                id,predict=clf.predict(gray_image[y:y+h,x:x+w])\n",
    "                confidence=int((100*(1-predict/300)))\n",
    "\n",
    "                if confidence>86:\n",
    "                    \n",
    "                    c=c-1\n",
    "                    cv2.putText(img,'MACHED!!',(x,y-55),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),3)               \n",
    "                    print(\"No of matched person= \"+str(-c))\n",
    "                else:\n",
    "                    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "                    cv2.putText(img,'Unknown face',(x,y-55),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),3)\n",
    "                \n",
    "                coord=[x,y,w,h]\n",
    "            \n",
    "            \n",
    "            return coord\n",
    "        \n",
    "        \n",
    "        path = ('../../../datasets/Test/')\n",
    "        def recognize(img,clf,facecascade):\n",
    "            c=0\n",
    "            sum=0\n",
    "            coord=draw_boundary(img,facecascade,1.1,10,(255,25,255),\"Face\",clf,c)\n",
    "            \n",
    "            #c=list(draw_boundary(img,facecascade,1.1,10,(255,25,255),\"Face\",clf,c)[:1])\n",
    "            \n",
    "            \n",
    "\n",
    "            return img\n",
    "        facecascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        clf=cv2.face.LBPHFaceRecognizer_create()\n",
    "        clf.read(\"N_classifier.xml\")\n",
    "        \n",
    "        while True:\n",
    "            for l, filename in enumerate(os.listdir(path)):\n",
    "                img=cv2.imread('../../../datasets/Test/user.'+ str(l)+'.jpg')\n",
    "                #img_main=cv2.VideoCapture(0)\n",
    "                #ret, img2=img_main.read()\n",
    "                \n",
    "                #img=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "                img=recognize(img,clf,facecascade)\n",
    "                cv2.imshow(\"welcome to face recognition\",img)\n",
    "                cv2.waitKey(delay=1000)\n",
    "                cv2.destroyAllWindows()\n",
    "            if cv2.waitKey(delay=1000):\n",
    "                break\n",
    "            \n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "if __name__== \"__main__\":\n",
    "    root=Tk()\n",
    "    obj=face_recognition(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09f592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dmsl19_ten]",
   "language": "python",
   "name": "conda-env-dmsl19_ten-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
